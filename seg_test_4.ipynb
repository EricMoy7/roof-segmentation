{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737268627.097584    2223 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737268627.100500    2223 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import SAM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from pycocotools import mask as maskUtils\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir = './roof_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data_dir, batch_size=8, shuffle=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.file_list = self._get_file_list()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _get_file_list(self):\n",
    "        file_list = []\n",
    "        for root, _, files in os.walk(self.data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    file_list.append(os.path.join(root, file))\n",
    "        return file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.file_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_files = self.file_list[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images, masks = self._load_data(batch_files)\n",
    "        return images, masks\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.file_list)\n",
    "\n",
    "    def _load_data(self, batch_files):\n",
    "        images = []\n",
    "        masks = []\n",
    "        for json_path in batch_files:\n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                image_path = os.path.join(os.path.dirname(json_path), data['image']['file_name'])\n",
    "                if os.path.exists(image_path):\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is not None:\n",
    "                        images.append(image / 255.0)  # Normalize the image\n",
    "                        # Create an empty mask\n",
    "                        mask = np.zeros((data['image']['height'], data['image']['width']), dtype=np.uint8)\n",
    "                        for annotation in data['annotations']:\n",
    "                            rle = annotation['segmentation']\n",
    "                            binary_mask = maskUtils.decode(rle)\n",
    "                            mask = np.maximum(mask, binary_mask)\n",
    "                        masks.append(mask / 255.0)  # Normalize the mask\n",
    "                    else:\n",
    "                        print(f\"Failed to read image: {image_path}\")\n",
    "                else:\n",
    "                    print(f\"File does not exist: {image_path}\")\n",
    "        return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_dir = os.path.join(extract_dir, 'train')\n",
    "# val_data_dir = os.path.join(extract_dir, 'valid')\n",
    "\n",
    "# train_images, train_masks = load_data(train_data_dir)\n",
    "# val_images, val_masks = load_data(val_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(extract_dir, 'train')\n",
    "val_data_dir = os.path.join(extract_dir, 'valid')\n",
    "\n",
    "train_generator = DataGenerator(train_data_dir, batch_size=8, shuffle=True)\n",
    "val_generator = DataGenerator(val_data_dir, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAM('./sam2.1_b.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust the number of epochs as needed\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust the learning rate as needed\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/roof-segmentation/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m checks\u001b[38;5;241m.\u001b[39mcheck_pip_update_available()\n\u001b[1;32m    789\u001b[0m overrides \u001b[38;5;241m=\u001b[39m yaml_load(checks\u001b[38;5;241m.\u001b[39mcheck_yaml(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides\n\u001b[1;32m    790\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;66;03m# NOTE: handle the case when 'cfg' includes 'data'.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: overrides\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_CFG_DICT[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m TASK2DATA[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask],\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask,\n\u001b[1;32m    795\u001b[0m }  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[1;32m    796\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,  # Adjust the number of epochs as needed\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    learning_rate=0.001  # Adjust the learning rate as needed\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
