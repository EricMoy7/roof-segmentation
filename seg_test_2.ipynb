{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg'\n",
    "\n",
    "from ultralytics import SAM, YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM model\n",
    "sam_model = SAM('./sam2.1_b.pt')\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO('./yolo11x-cls.pt')\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = './image.png'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 3649.4ms\n",
      "Speed: 4.9ms preprocess, 3649.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Run SAM inference to get segmentation masks\n",
    "sam_results = sam_model.predict(image_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 19)\n"
     ]
    }
   ],
   "source": [
    "masks = sam_results[0].masks  # Adjust based on actual output structure\n",
    "# output_masks = masks.data.cpu().numpy()  # Ensure the mask is on the CPU and convert to numpy array\n",
    "output_masks = masks.xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 cleaver 0.03, space_shuttle 0.02, oboe 0.01, cassette 0.01, notebook 0.01, 86.5ms\n",
      "Speed: 6.2ms preprocess, 86.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Band_Aid 0.33, digital_clock 0.04, rule 0.03, envelope 0.02, street_sign 0.02, 8.9ms\n",
      "Speed: 4.4ms preprocess, 8.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 digital_clock 0.08, digital_watch 0.07, Band_Aid 0.07, analog_clock 0.03, spotlight 0.03, 8.1ms\n",
      "Speed: 4.4ms preprocess, 8.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 jellyfish 0.32, sea_urchin 0.06, ping-pong_ball 0.04, digital_clock 0.03, nematode 0.03, 9.8ms\n",
      "Speed: 4.9ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Band_Aid 0.05, cleaver 0.05, loudspeaker 0.04, notebook 0.02, window_shade 0.02, 8.2ms\n",
      "Speed: 4.5ms preprocess, 8.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Band_Aid 0.05, digital_clock 0.04, loudspeaker 0.03, spotlight 0.02, street_sign 0.02, 8.6ms\n",
      "Speed: 3.9ms preprocess, 8.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 velvet 0.03, nematode 0.02, matchstick 0.01, safety_pin 0.01, screw 0.01, 8.9ms\n",
      "Speed: 4.1ms preprocess, 8.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Band_Aid 0.03, street_sign 0.03, loudspeaker 0.02, mortarboard 0.02, digital_clock 0.02, 8.7ms\n",
      "Speed: 4.0ms preprocess, 8.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 loudspeaker 0.03, mortarboard 0.03, cleaver 0.02, Band_Aid 0.02, matchstick 0.02, 8.6ms\n",
      "Speed: 4.1ms preprocess, 8.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 spotlight 0.04, Band_Aid 0.03, mortarboard 0.03, safety_pin 0.03, digital_clock 0.03, 9.2ms\n",
      "Speed: 3.7ms preprocess, 9.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Band_Aid 0.03, digital_clock 0.03, loudspeaker 0.02, spotlight 0.01, digital_watch 0.01, 9.6ms\n",
      "Speed: 4.1ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Band_Aid 0.05, digital_clock 0.04, loudspeaker 0.03, spotlight 0.02, street_sign 0.02, 8.5ms\n",
      "Speed: 3.9ms preprocess, 8.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 cleaver 0.05, mortarboard 0.04, loudspeaker 0.03, notebook 0.03, envelope 0.03, 9.7ms\n",
      "Speed: 3.9ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 bubble 0.15, nematode 0.06, jellyfish 0.04, hammerhead 0.02, matchstick 0.02, 8.9ms\n",
      "Speed: 4.4ms preprocess, 8.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 kite 0.03, screw 0.02, nematode 0.01, tick 0.01, nail 0.01, 8.3ms\n",
      "Speed: 3.9ms preprocess, 8.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 velvet 0.03, nematode 0.02, matchstick 0.01, safety_pin 0.01, screw 0.01, 9.4ms\n",
      "Speed: 4.1ms preprocess, 9.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 cleaver 0.06, hatchet 0.02, ocarina 0.02, lighter 0.02, can_opener 0.02, 8.9ms\n",
      "Speed: 5.0ms preprocess, 8.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 screw 0.05, nail 0.02, digital_clock 0.01, tick 0.01, switch 0.01, 10.8ms\n",
      "Speed: 4.5ms preprocess, 10.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 notebook 0.01, laptop 0.01, picket_fence 0.01, matchstick 0.01, digital_clock 0.01, 9.5ms\n",
      "Speed: 4.3ms preprocess, 9.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Create a figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Display the original image\n",
    "plt.imshow(image_rgb)\n",
    "\n",
    "# Overlay each mask on the original image with transparency\n",
    "for idx, mk in enumerate(output_masks):\n",
    "    mask = output_masks[idx]\n",
    "    plt.imshow(mask, cmap='jet', alpha=0.5)  # Use alpha for transparency\n",
    "\n",
    "    # Convert mask to the correct type\n",
    "    mask_uint8 = cv2.fillPoly(np.zeros(image_rgb.shape[:2], dtype=np.uint8), [mask.astype(np.int32)], 1)\n",
    "\n",
    "    # Extract the segment from the original image\n",
    "    segment = cv2.bitwise_and(image_rgb, image_rgb, mask=mask_uint8)\n",
    "\n",
    "    # Run YOLO inference on the segment to get labels\n",
    "    yolo_results = yolo_model.predict(segment)\n",
    "    labels = yolo_results[0].names  # Adjust based on actual output structure\n",
    "\n",
    "    # Display the label\n",
    "    plt.text(10, 10 + idx * 20, f'Label {idx}: {labels[0]}', color='white', fontsize=12, backgroundcolor='black')\n",
    "\n",
    "plt.title('Original Image with All Masks and Labels')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
